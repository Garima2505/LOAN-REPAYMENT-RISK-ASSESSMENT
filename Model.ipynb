{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('PredictDefaulter').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data. \n",
    "Reading the data that is cleaned earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('Data/CleanedDataOutput', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_amnt: double (nullable = true)\n",
      " |-- funded_amnt: double (nullable = true)\n",
      " |-- funded_amnt_inv: double (nullable = true)\n",
      " |-- term: string (nullable = true)\n",
      " |-- int_rate: double (nullable = true)\n",
      " |-- installment: double (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- emp_length: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: double (nullable = true)\n",
      " |-- verification_status: string (nullable = true)\n",
      " |-- loan_status: string (nullable = true)\n",
      " |-- pymnt_plan: string (nullable = true)\n",
      " |-- addr_state: string (nullable = true)\n",
      " |-- dti: double (nullable = true)\n",
      " |-- delinq_2yrs: integer (nullable = true)\n",
      " |-- fico_range_low: double (nullable = true)\n",
      " |-- fico_range_high: double (nullable = true)\n",
      " |-- pub_rec: integer (nullable = true)\n",
      " |-- revol_bal: double (nullable = true)\n",
      " |-- revol_util: double (nullable = true)\n",
      " |-- initial_list_status: string (nullable = true)\n",
      " |-- total_pymnt: double (nullable = true)\n",
      " |-- total_pymnt_inv: double (nullable = true)\n",
      " |-- total_rec_prncp: double (nullable = true)\n",
      " |-- total_rec_int: double (nullable = true)\n",
      " |-- application_type: string (nullable = true)\n",
      " |-- acc_now_delinq: double (nullable = true)\n",
      " |-- tot_cur_bal: double (nullable = true)\n",
      " |-- total_rev_hi_lim: double (nullable = true)\n",
      " |-- avg_cur_bal: double (nullable = true)\n",
      " |-- bc_open_to_buy: double (nullable = true)\n",
      " |-- bc_util: double (nullable = true)\n",
      " |-- chargeoff_within_12_mths: double (nullable = true)\n",
      " |-- delinq_amnt: double (nullable = true)\n",
      " |-- mort_acc: double (nullable = true)\n",
      " |-- num_accts_ever_120_pd: double (nullable = true)\n",
      " |-- num_actv_bc_tl: double (nullable = true)\n",
      " |-- num_actv_rev_tl: double (nullable = true)\n",
      " |-- num_bc_sats: double (nullable = true)\n",
      " |-- num_bc_tl: double (nullable = true)\n",
      " |-- num_il_tl: double (nullable = true)\n",
      " |-- num_op_rev_tl: double (nullable = true)\n",
      " |-- num_rev_accts: double (nullable = true)\n",
      " |-- num_rev_tl_bal_gt_0: double (nullable = true)\n",
      " |-- num_sats: double (nullable = true)\n",
      " |-- pct_tl_nvr_dlq: double (nullable = true)\n",
      " |-- pub_rec_bankruptcies: double (nullable = true)\n",
      " |-- tax_liens: double (nullable = true)\n",
      " |-- tot_hi_cred_lim: double (nullable = true)\n",
      " |-- total_bal_ex_mort: double (nullable = true)\n",
      " |-- total_bc_limit: double (nullable = true)\n",
      " |-- total_il_high_credit_limit: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loan_amnt': 0,\n",
       " 'funded_amnt': 0,\n",
       " 'funded_amnt_inv': 0,\n",
       " 'term': 0,\n",
       " 'int_rate': 0,\n",
       " 'installment': 0,\n",
       " 'grade': 0,\n",
       " 'emp_length': 0,\n",
       " 'home_ownership': 0,\n",
       " 'annual_inc': 0,\n",
       " 'verification_status': 0,\n",
       " 'loan_status': 0,\n",
       " 'pymnt_plan': 0,\n",
       " 'addr_state': 0,\n",
       " 'dti': 0,\n",
       " 'delinq_2yrs': 0,\n",
       " 'fico_range_low': 0,\n",
       " 'fico_range_high': 0,\n",
       " 'pub_rec': 0,\n",
       " 'revol_bal': 0,\n",
       " 'revol_util': 0,\n",
       " 'initial_list_status': 0,\n",
       " 'total_pymnt': 0,\n",
       " 'total_pymnt_inv': 0,\n",
       " 'total_rec_prncp': 0,\n",
       " 'total_rec_int': 0,\n",
       " 'application_type': 0,\n",
       " 'acc_now_delinq': 0,\n",
       " 'tot_cur_bal': 0,\n",
       " 'total_rev_hi_lim': 0,\n",
       " 'avg_cur_bal': 0,\n",
       " 'bc_open_to_buy': 0,\n",
       " 'bc_util': 0,\n",
       " 'chargeoff_within_12_mths': 0,\n",
       " 'delinq_amnt': 0,\n",
       " 'mort_acc': 0,\n",
       " 'num_accts_ever_120_pd': 0,\n",
       " 'num_actv_bc_tl': 0,\n",
       " 'num_actv_rev_tl': 0,\n",
       " 'num_bc_sats': 0,\n",
       " 'num_bc_tl': 0,\n",
       " 'num_il_tl': 0,\n",
       " 'num_op_rev_tl': 0,\n",
       " 'num_rev_accts': 0,\n",
       " 'num_rev_tl_bal_gt_0': 0,\n",
       " 'num_sats': 0,\n",
       " 'pct_tl_nvr_dlq': 0,\n",
       " 'pub_rec_bankruptcies': 0,\n",
       " 'tax_liens': 0,\n",
       " 'tot_hi_cred_lim': 0,\n",
       " 'total_bal_ex_mort': 0,\n",
       " 'total_bc_limit': 0,\n",
       " 'total_il_high_credit_limit': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check null values\n",
    "data_null = data.agg(*[f.count(f.when(f.isnull(c), c)).alias(c) for c in data.columns[:]])\n",
    "null_values = data_null.head(1)[0]\n",
    "null_values.asDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity we will be only considering applicants that have taken loan Individually (where application_type = 'Individual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2215254"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_individual = data.filter(data['application_type'] == 'Individual').drop('application_type')\n",
    "data_individual.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 states with the applicants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|addr_state| count|\n",
      "+----------+------+\n",
      "|        CA|310445|\n",
      "|        TX|185967|\n",
      "|        NY|183661|\n",
      "|        FL|157411|\n",
      "|        IL| 90197|\n",
      "|        NJ| 83029|\n",
      "|        PA| 74536|\n",
      "|        GA| 73234|\n",
      "|        OH| 72791|\n",
      "|        VA| 61793|\n",
      "+----------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# addr_state\n",
    "data_individual.groupBy('addr_state').count().orderBy(desc('count')).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of applicants are from California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|loan_status       |count  |\n",
      "+------------------+-------+\n",
      "|Fully Paid        |980714 |\n",
      "|Default           |36     |\n",
      "|In Grace Period   |10313  |\n",
      "|Charged Off       |238633 |\n",
      "|Late (31-120 days)|23993  |\n",
      "|Current           |1104088|\n",
      "|Late (16-30 days) |4856   |\n",
      "+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loan_status\n",
    "data.groupBy('loan_status').count().show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meaning of different loan status:\n",
    "* Current: Loan is up to date on all outstanding payments. \n",
    "* In Grace Period: Loan is past due but within the 15-day grace period.  \n",
    "* Late (16-30): Loan has not been current for 16 to 30 days.\n",
    "* Late (31-120): Loan has not been current for 31 to 120 days.\n",
    "* Fully paid: Loan has been fully repaid, either at the expiration of the 3- or 5-year year term or as a result of a prepayment.\n",
    "* Default: Loan has not been current for an extended period of time.\n",
    "* Charged Off: Loan for which there is no longer a reasonable expectation of further payments. Upon Charge Off, the remaining principal balance of the Note is deducted from the account balance.\n",
    "\n",
    "### Difference between \"Charged Off\" and \"Default\"\n",
    "Loans that are in \"Default\" are loans for which borrowers have failed to make payments for an extended period of time.\n",
    " \n",
    "A loan becomes “Charged Off” when there is no longer a reasonable expectation of further payments.  Charge Off typically occurs when a loan is 120 days or more past due and there is no reasonable expectation of sufficient payment to prevent the charge off.  In certain circumstances, loans may be charged off at an earlier or later date.\n",
    " \n",
    "A loan that is in “Default” will still appear in your Notes, in the status of “Default,” while a loan that has been “Charged Off” will appear as charged off, and the remaining principal balance of the Note will be deducted from your account balance.\n",
    "\n",
    "Note: For simplicity, not considerating the applicants who \"Does not meet the credit policy.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing how many applicants currently paying the loan might become defaulter and separating out the applicants with \"loan_status\" as \"Current\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data with \"current\" status will later be use for evaluation purpose.\n",
    "df_current = data_individual.filter(data[\"loan_status\"] == \"Current\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_current_applicants = df_current.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|loan_status       |\n",
      "+------------------+\n",
      "|Fully Paid        |\n",
      "|Default           |\n",
      "|In Grace Period   |\n",
      "|Charged Off       |\n",
      "|Late (31-120 days)|\n",
      "|Late (16-30 days) |\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = data_individual.filter(data[\"loan_status\"] != 'Current')\n",
    "df.select('loan_status').distinct().show(truncate=False)\n",
    "total_applicant = df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To predict the risk whether an applicatant will pay the loan or not, considering \"loan_status\" in 3 categories: \n",
    "\n",
    "* safe : no risk in repayment (Applicant will fully pay the loan without any distress)\n",
    "* low : low risk (Applicant might face some distress during the repayment of the loan)\n",
    "* high : high risk (Applicant might face high distress inhibiting the ability to repay the loan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('default_risk', f.when(f.col('loan_status') == \"Fully Paid\", 'safe')\n",
    "                   .when(((f.col('loan_status') == \"In Grace Period\") | \n",
    "                                   (f.col('loan_status') == \"Late (31-120 days)\") |\n",
    "                         (f.col('loan_status') == 'Late (16-30 days)')) , \"low\")\n",
    "                   .otherwise(\"high\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+\n",
      "|       loan_status|default_risk|\n",
      "+------------------+------------+\n",
      "|       Charged Off|        high|\n",
      "|           Default|        high|\n",
      "| Late (16-30 days)|         low|\n",
      "|   In Grace Period|         low|\n",
      "|Late (31-120 days)|         low|\n",
      "|        Fully Paid|        safe|\n",
      "+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('loan_status', 'default_risk').distinct().orderBy('default_risk').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|summary|       annual_inc|         loan_amnt|          int_rate|               dti|          mort_acc|\n",
      "+-------+-----------------+------------------+------------------+------------------+------------------+\n",
      "|  count|          1228636|           1228636|           1228636|           1228636|           1228636|\n",
      "|   mean| 78695.5284027327|14740.847777535413|13.303155751592813|18.213233423080506|1.6445106606024893|\n",
      "| stddev|53904.98488219384| 8770.525798898754| 4.816573433807678| 8.302813179558434|1.9840999102619745|\n",
      "|    min|           2000.0|            1000.0|              5.31|               1.0|               0.0|\n",
      "|    max|        4000000.0|           40000.0|             30.99|             49.96|              47.0|\n",
      "+-------+-----------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(['annual_inc', 'loan_amnt', 'int_rate', 'dti', 'mort_acc']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|emp_length| count|\n",
      "+----------+------+\n",
      "| 10+ years|435362|\n",
      "|   2 years|117840|\n",
      "|   3 years|104282|\n",
      "|  < 1 year|101352|\n",
      "|    1 year| 86050|\n",
      "|   5 years| 80768|\n",
      "|   4 years| 77105|\n",
      "|   6 years| 60118|\n",
      "|   8 years| 59046|\n",
      "|   7 years| 57346|\n",
      "|   9 years| 49367|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('emp_length').count().orderBy(desc('count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of the applicants have more than 10 years of employement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing Applicants that are 'safe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_safe = df.filter(df['default_risk'] == 'safe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_risk_safe = risk_safe.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------------------+\n",
      "|emp_length| count|        percentage|\n",
      "+----------+------+------------------+\n",
      "| 10+ years|344847| 35.89038273000331|\n",
      "|   2 years| 91502|  9.52318506630698|\n",
      "|   3 years| 80860| 8.415605609293593|\n",
      "|  < 1 year| 77718| 8.088598030461037|\n",
      "|    1 year| 66154|  6.88506027055662|\n",
      "|   5 years| 62902|6.5466043041774125|\n",
      "|   4 years| 59819| 6.225737224119879|\n",
      "|   6 years| 47124| 4.904489224985793|\n",
      "|   8 years| 46177|4.8059290158341605|\n",
      "|   7 years| 45097| 4.693526665376121|\n",
      "|   9 years| 38634| 4.020881858885093|\n",
      "+----------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "risk_safe.groupBy('emp_length').count().orderBy(desc('count')).withColumn('percentage', \n",
    "                                                                          (f.col('count') / total_risk_safe)*100).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35% of the total applicants that have fully paid the loan and have employment length more than 10 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------------------+\n",
      "|addr_state| count|        percentage|\n",
      "+----------+------+------------------+\n",
      "|        CA|140475|14.620111278326952|\n",
      "|        TX| 80019| 8.328077482686917|\n",
      "|        NY| 75810| 7.890020544651834|\n",
      "|        FL| 65768| 6.844886837892913|\n",
      "|        IL| 38042|  3.95926871863402|\n",
      "+----------+------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "risk_safe.groupBy('addr_state').count().orderBy(desc('count')).withColumn('percentage', \n",
    "                                                                          (f.col('count') / total_risk_safe)*100).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------------------+\n",
      "|     term| count|        percentage|\n",
      "+---------+------+------------------+\n",
      "|36 months|761950| 79.30089901065116|\n",
      "|60 months|198884|20.699100989348835|\n",
      "+---------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# term\n",
    "risk_safe.groupBy('term').count().withColumn('percentage', (f.col('count') / total_risk_safe)*100).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "79% of applicants preferred 36 months term period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+--------------------+\n",
      "|home_ownership| count|          percentage|\n",
      "+--------------+------+--------------------+\n",
      "|      MORTGAGE|493305|   51.34133471546593|\n",
      "|          RENT|367241|   38.22106628200084|\n",
      "|           OWN| 99754|  10.382022284806741|\n",
      "|           ANY|   467| 0.04860360894805971|\n",
      "|          NONE|    34|0.003538592514419...|\n",
      "|         OTHER|    33|0.003434516263995...|\n",
      "+--------------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# home_ownership\n",
    "risk_safe.groupBy('home_ownership').count().withColumn('percentage', \n",
    "                                                       (f.col('count') / total_risk_safe)*100).orderBy(\n",
    "                                                                                            desc('count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of the applicants have mortaged their home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|verification_status| count|\n",
      "+-------------------+------+\n",
      "|    Source Verified|387522|\n",
      "|       Not Verified|313583|\n",
      "|           Verified|259729|\n",
      "+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# verification_status\n",
    "risk_safe.groupBy('verification_status').count().orderBy(desc('count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applicants on 'High' risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_high = df.filter(df['default_risk'] == 'high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_risk_high = risk_high.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------+\n",
      "|emp_length|count|        percentage|\n",
      "+----------+-----+------------------+\n",
      "| 10+ years|78987| 33.88502078480328|\n",
      "|   2 years|22774| 9.769930030930533|\n",
      "|   3 years|20313|  8.71417356275981|\n",
      "|  < 1 year|20076| 8.612501769603995|\n",
      "|    1 year|17250|  7.40016216007516|\n",
      "|   5 years|15452| 6.628829315796021|\n",
      "|   4 years|14835|6.3641394576646375|\n",
      "|   8 years|11519| 4.941592343298885|\n",
      "|   6 years|11341| 4.865231249705066|\n",
      "|   7 years|10909| 4.679905449522314|\n",
      "|   9 years| 9647| 4.138513875840294|\n",
      "+----------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "risk_high.groupBy('emp_length').count().orderBy(\n",
    "    desc('count')).withColumn('percentage', \n",
    "                               (f.col('count') / total_risk_high)*100).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to applicants that are 'safe', applicants at high risk also have majority of the applicants with more than 10 years of experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------------------+\n",
      "|addr_state|count|        percentage|\n",
      "+----------+-----+------------------+\n",
      "|        CA|33443| 14.34687670257354|\n",
      "|        NY|21244| 9.113567821949955|\n",
      "|        TX|19470| 8.352530855458745|\n",
      "|        FL|17449| 7.485532146733418|\n",
      "|        NJ| 9059|3.8862648700359927|\n",
      "+----------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "risk_high.groupBy('addr_state').count().orderBy(desc('count')).withColumn('percentage', \n",
    "                                                                          (f.col('count') / total_risk_high)*100).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of the applicants are from California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|     term| count|\n",
      "+---------+------+\n",
      "|36 months|139029|\n",
      "|60 months| 94074|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# term\n",
    "risk_high.groupBy('term').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+--------------------+\n",
      "|home_ownership| count|          percentage|\n",
      "+--------------+------+--------------------+\n",
      "|          RENT|109042|   46.77846273964728|\n",
      "|      MORTGAGE| 99357|   42.62364705730943|\n",
      "|           OWN| 24590|  10.548984783550619|\n",
      "|           ANY|   100|0.042899490783044406|\n",
      "|         OTHER|     8|0.003431959262643...|\n",
      "|          NONE|     6|0.002573969446982664|\n",
      "+--------------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# home_ownership\n",
    "risk_high.groupBy('home_ownership').count().withColumn('percentage', \n",
    "                               (f.col('count') / total_risk_high)*100).orderBy(desc('count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of the applicants at high risk rented the house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|verification_status| count|\n",
      "+-------------------+------+\n",
      "|    Source Verified|101290|\n",
      "|           Verified| 79511|\n",
      "|       Not Verified| 52302|\n",
      "+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# verification_status\n",
    "risk_high.groupBy('verification_status').count().orderBy(desc('count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing applicants with 'safe' and 'high' risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+------------------+\n",
      "|summary|       tot_cur_bal|              dti|   fico_range_low|   fico_range_high|\n",
      "+-------+------------------+-----------------+-----------------+------------------+\n",
      "|  count|            960834|           960834|           960834|            960834|\n",
      "|   mean|149146.79575035855|17.75943490759058|697.4491847707304| 701.4493127845185|\n",
      "| stddev|163503.35628624592|8.182468059114372| 32.1849966404692|32.185585498192346|\n",
      "|    min|               0.0|              1.0|            660.0|             664.0|\n",
      "|    max|         5445012.0|            49.96|            845.0|             850.0|\n",
      "+-------+------------------+-----------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "risk_safe.describe(['tot_cur_bal', 'dti', 'fico_range_low', 'fico_range_high']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+-----------------+\n",
      "|summary|       tot_cur_bal|              dti|   fico_range_low|  fico_range_high|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+\n",
      "|  count|            233103|           233103|           233103|           233103|\n",
      "|   mean|121889.50687035345|19.99958726399929|687.0949108334084|691.0949666027465|\n",
      "| stddev|136314.01115054343|8.500327836422429|25.07914407358612| 25.0794963232977|\n",
      "|    min|               0.0|              1.0|            660.0|            664.0|\n",
      "|    max|         3437283.0|            49.92|            845.0|            850.0|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "risk_high.describe(['tot_cur_bal', 'dti', 'fico_range_low', 'fico_range_high']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we can see, the average total current balance ('tot_cur_bal') of applicants is higher for the applicants that are safe.\n",
    "* The Depth to income ratio ('dti) on average is higher for applicants at high risk, i.e., these applicants are earning less campared to their debt\n",
    "* Applicants with risk safe have higher FICO score as compare to applicants to high risk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+------------------+--------------------+\n",
      "|summary|       delinq_2yrs|            pub_rec|       delinq_amnt|pub_rec_bankruptcies|\n",
      "+-------+------------------+-------------------+------------------+--------------------+\n",
      "|  count|            960834|             960834|            960834|              960834|\n",
      "|   mean| 0.319005155937446|0.20838771317417992|14.194593446942969| 0.12985489689165872|\n",
      "| stddev|0.8786005595481192| 0.5913702714030439| 773.6206934564974|  0.3713156286661652|\n",
      "|    min|                 0|                  0|               0.0|                 0.0|\n",
      "|    max|                39|                 63|          185408.0|                12.0|\n",
      "+-------+------------------+-------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "risk_safe.describe(['delinq_2yrs', 'pub_rec', 'delinq_amnt', 'pub_rec_bankruptcies']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+------------------+--------------------+\n",
      "|summary|        delinq_2yrs|            pub_rec|       delinq_amnt|pub_rec_bankruptcies|\n",
      "+-------+-------------------+-------------------+------------------+--------------------+\n",
      "|  count|             233103|             233103|            233103|              233103|\n",
      "|   mean|0.36051445069347027|0.24633745597439757|20.694813022569424| 0.15174836874686298|\n",
      "| stddev| 0.9512137192283301| 0.6653008059429222|1026.5632144741928| 0.40478093739772136|\n",
      "|    min|                  0|                  0|               0.0|                 0.0|\n",
      "|    max|                 27|                 86|          249925.0|                11.0|\n",
      "+-------+-------------------+-------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "risk_high.describe(['delinq_2yrs', 'pub_rec', 'delinq_amnt', 'pub_rec_bankruptcies']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Applicants with higher risk have more past due amount owed for the accounts on which the borrower is now delinquent ('delinq_amnt') as compare to applicants that are safe.\n",
    "* Applicants with higher risk have more public record for bankruptcies('pub_rec_bankruptcies') and number of derogatory public records ('pub_rec') as compare to safe applicants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing 'default_risk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|label|default_risk|\n",
      "+-----+------------+\n",
      "|  1.0|        high|\n",
      "|  2.0|         low|\n",
      "|  0.0|        safe|\n",
      "+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert loan_default into label indices using the StringIndexer\n",
    "label_stringIndex = StringIndexer(inputCol=\"default_risk\", outputCol=\"label\")\n",
    "df_label = label_stringIndex.fit(df).transform(df)\n",
    "df_label.select('label', 'default_risk').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df_label.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+-----------------+\n",
      "|default_risk| count|       percentage|\n",
      "+------------+------+-----------------+\n",
      "|         low| 24223|2.817512474846754|\n",
      "|        safe|672497| 78.2218836146232|\n",
      "|        high|163010|18.96060391053005|\n",
      "+------------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.groupBy('default_risk').count().withColumn('percentage', \n",
    "                                                             (f.col('count')*100/train_count)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is skewed with approx 19% data of applicants at high risk, 78% safe and 3% applicants at lower risk which makes the data highly Unbalanced. Oversampling the applicants data that are at 'low' risk  and undersampling the applicants that are'safe' can help balance the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating out different risk categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "high = train_data.filter(train_data['default_risk'] == 'high')\n",
    "high_count = high.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = train_data.filter(train_data['default_risk'] == 'low')\n",
    "low_count = low.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe = train_data.filter(train_data['default_risk'] == 'safe')\n",
    "safe_count = safe.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling data from \"low\" risk status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"low\" risk count after oversampling 145338\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, array, lit\n",
    "\n",
    "oversample_ratio = int(high_count / low_count)\n",
    "low_range = range(oversample_ratio)\n",
    "oversampled_low = low.withColumn(\"dummy\", explode(array([lit(x) for x in low_range]))).drop('dummy')\n",
    "print(f'\"low\" risk count after oversampling {oversampled_low.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling data from \"safe\" risk status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"safe\" count after undersampling 162806\n"
     ]
    }
   ],
   "source": [
    "undersample_ratio = float(high_count / safe_count)\n",
    "undersample_safe = safe.sample(withReplacement = False, fraction = undersample_ratio)\n",
    "print(f'\"safe\" count after undersampling {undersample_safe.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining all the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+------------------+\n",
      "|default_risk| count|        percentage|\n",
      "+------------+------+------------------+\n",
      "|         low|145338|16.905074849080524|\n",
      "|        safe|162806|18.936875530689868|\n",
      "|        high|163010| 18.96060391053005|\n",
      "+------------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_train_df = oversampled_low.union(undersample_safe).union(high)\n",
    "final_train_df.groupBy('default_risk').count().withColumn('percentage', \n",
    "                                                             (f.col('count')*100/train_count)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorIndexer, VectorAssembler, OneHotEncoder\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['term', 'grade',\n",
    "                       'emp_length', 'home_ownership', \n",
    "                       'verification_status', 'pymnt_plan',\n",
    "                       'addr_state', 'initial_list_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns=['loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n",
    "                 'int_rate', 'installment', 'annual_inc',\n",
    "                 'dti', 'delinq_2yrs', 'fico_range_low',\n",
    "                 'fico_range_high', 'pub_rec', 'revol_bal',\n",
    "                 'revol_util', 'total_pymnt', 'total_pymnt_inv',\n",
    "                 'total_rec_prncp', 'total_rec_int', 'acc_now_delinq',\n",
    "                 'tot_cur_bal', 'total_rev_hi_lim', 'avg_cur_bal',\n",
    "                 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths',\n",
    "                 'delinq_amnt', 'mort_acc', 'num_accts_ever_120_pd',\n",
    "                 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats',\n",
    "                 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
    "                 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats',\n",
    "                 'pct_tl_nvr_dlq', 'pub_rec_bankruptcies', 'tax_liens',\n",
    "                 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
    "                 'total_il_high_credit_limit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = final_train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = [] # stages in our Pipeline\n",
    "for categoricalCol in categorical_columns:\n",
    "    # Category Indexing with StringIndexer\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\").setHandleInvalid(\"skip\")\n",
    "    # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    # Add stages.  These are not run here, but will run all at once later on.\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "assemblerInputs = [c + \"classVec\" for c in categorical_columns] + numeric_columns\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_70b6470bda3d,\n",
       " OneHotEncoder_5d83bbd3c0bc,\n",
       " StringIndexer_6fc41add62fa,\n",
       " OneHotEncoder_b1f3fa507b3a,\n",
       " StringIndexer_d0157ec10ea0,\n",
       " OneHotEncoder_9d587c6396dc,\n",
       " StringIndexer_08bafa4cf3a5,\n",
       " OneHotEncoder_951d7f2f109c,\n",
       " StringIndexer_af280ed71c1b,\n",
       " OneHotEncoder_33677ab5838c,\n",
       " StringIndexer_1b86e1b16315,\n",
       " OneHotEncoder_4f6fc6e0eaba,\n",
       " StringIndexer_b3dd542f4a9b,\n",
       " OneHotEncoder_09d6066d328b,\n",
       " StringIndexer_b37e5a7e406b,\n",
       " OneHotEncoder_1ebe5a8fee94,\n",
       " VectorAssembler_2a34bd1ac58b]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline().setStages(stages)\n",
    "pipelineModel = pipeline.fit(final_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prep_df = pipelineModel.transform(final_train_df)\n",
    "test_prep_df = pipelineModel.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping relevant columns\n",
    "selected_columns = [\"features\"] + columns\n",
    "train_prep_df = train_prep_df.select(selected_columns)\n",
    "\n",
    "test_prep_df = test_prep_df.select(selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifing which model will be best for the prediction. For this we are using 3 classification Algorithms:\n",
    "* Logistic Regression\n",
    "* Decision Tree\n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol='label')\n",
    "\n",
    "# fit the model\n",
    "lr_model = lr.fit(train_prep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8459696829486749"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model summary\n",
    "training_summary = lr_model.summary\n",
    "training_summary.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "lr_predictions = lr_model.transform(test_prep_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Accuracy**\n",
    "\n",
    "Checking model accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9452651895062699"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MulticlassClassificationEvaluator for calculating Accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label',\n",
    "                                             metricName='accuracy')\n",
    "evaluator.evaluate(lr_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Fit\n",
    "dt_model = dt.fit(train_prep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "dt_predictions = dt_model.transform(test_prep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(118, {74: 0.0437, 75: 0.2191, 77: 0.0316, 79: 0.0161, 89: 0.0157, 90: 0.5858, 91: 0.088})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9179357343063003"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(dt_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on different number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with number of trees 50 is: 0.8887521482437261\n",
      "Accuracy with number of trees 100 is: 0.8823196152949532\n",
      "Accuracy with number of trees 200 is: 0.8923058990637182\n",
      "Accuracy with number of trees 300 is: 0.8876461754484882\n",
      "Accuracy with number of trees 400 is: 0.8895003063110928\n"
     ]
    }
   ],
   "source": [
    "numTrees = [50, 100, 200, 300, 400]\n",
    "for num in numTrees:\n",
    "    rf = RandomForestClassifier(numTrees=num)\n",
    "    \n",
    "    # model\n",
    "    rf_model = rf.fit(train_prep_df)\n",
    "    \n",
    "    # Predict\n",
    "    rf_predictions = rf_model.transform(test_prep_df)\n",
    "    \n",
    "    # Accuracy\n",
    "    acc = evaluator.evaluate(rf_predictions)\n",
    "    print(f'Accuracy with number of trees {num} is: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating whether the applicant, who is under current status, will face any financial distress in the future i.e. in the context of repaying the loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_current_df = pipelineModel.transform(df_current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "lr_risk_prediction = lr_model.transform(predicted_current_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IndexToString \n",
    "\n",
    "converter = IndexToString(inputCol=\"prediction\", outputCol=\"predicted_label\", labels=['safe', 'high', 'low'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+------+\n",
      "|prediction|predicted_label| count|\n",
      "+----------+---------------+------+\n",
      "|       1.0|           high|194151|\n",
      "|       2.0|            low|760471|\n",
      "|       0.0|           safe| 31996|\n",
      "+----------+---------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original_label_df = converter.transform(lr_risk_prediction)\n",
    "original_label_df.groupBy('prediction', \"predicted_label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_risk_applicants = original_label_df.filter(original_label_df['predicted_label'] == 'high').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of people that may default the loan : 19.6784368418172\n"
     ]
    }
   ],
   "source": [
    "print(f\"percentage of people that may default the loan : {(high_risk_applicants / total_current_applicants)*100 }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
